{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "name": "ml-modelo-regressao-carros-usados",
    "notebookId": 1148180762024892,
    "colab": {
      "name": "ml-modelo-regressao-carros-usados.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelturon/pocs/blob/master/ml_modelo_regressao_carros_usados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvl7_kH_AMQy",
        "colab_type": "text"
      },
      "source": [
        "#Machine Learning\n",
        "###Exemplo de modelo de regressão p/ previsão de preços de venda de carros usados\n",
        "* Este tutorial foi inspirado no repositório [Machine Learning](https://github.com/lfbraz/azure-databricks/blob/master/notebooks/ml-modelo-regressao-carros-usados.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufSmEwgoAMQ5",
        "colab_type": "text"
      },
      "source": [
        "### Neste tutorial faremos uma [regressão linear simples](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear_simples) em que o objetivo será prever o PREÇO (y) de venda de um determinado modelo de veículo se baseando em algumas variáveis de entrada (X) \n",
        "\n",
        "A base de dados utilizada pode ser obtida no [link](https://github.com/lfbraz/machine-learning-tutorial/blob/master/datasets/dataset-carros-usados.csv) e foi baseada na versão [original](https://databricksdemostore.blob.core.windows.net/data/02.02/UsedCars.csv) disponibilizada pela Databricks, em que foi adaptada e traduzida para Português-Brasil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhwVWjSvAMQ6",
        "colab_type": "text"
      },
      "source": [
        "##Importar base de dados\n",
        "Utilizarei o [Google Colab](https://colab.research.google.com/) para treino do modelo, porém este tutorial pode ser utilizado com qualquer plataforma (sendo necessário apenas que o método de importação seja adaptado)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0pHRftGLF-",
        "colab_type": "text"
      },
      "source": [
        "# **Running Pyspark in Colab**\n",
        "\n",
        "Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Scala, Java, Python, and R, and an optimized engine that supports general computation graphs for data analysis. It also supports a rich set of higher-level tools including Spark SQL for SQL and DataFrames, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for stream processing.\n",
        "\n",
        "https://spark.apache.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4vZ32bUGSP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiY9D7fXAMRB",
        "colab_type": "text"
      },
      "source": [
        "##Ler o arquivo .csv em um Spark DataFrame\n",
        "\n",
        "Utilizaremos as segmentos opções: <br/>\n",
        "<br/>\n",
        "* format: CSV\n",
        "* inferSchema: true / Permite que os tipos de dados sejam automaticamente inferidos\n",
        "* header: true / Primeira linha será entendida como o cabeçalho\n",
        "* sep: \";\" / Será utilizado como delimitador de colunas o carácter \";\"\n",
        "* load: path / O caminho do arquivo que será carregado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGn4CIpfAMRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "filename = \"dataset-carros-usados.csv\"\n",
        "url = \"https://raw.githubusercontent.com/lfbraz/machine-learning-tutorial/master/datasets/{}\".format(filename)\n",
        "\n",
        "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "file_type = \"csv\"\n",
        "infer_schema = \"true\"\n",
        "first_row_is_header = \"true\"\n",
        "delimiter = \";\"\n",
        "\n",
        "carros_usados = spark.read.format(file_type) \\\n",
        "                     .option(\"inferSchema\", infer_schema) \\\n",
        "                     .option(\"header\", first_row_is_header) \\\n",
        "                     .option(\"sep\", delimiter) \\\n",
        "                     .load(\"file://\"+SparkFiles.get(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMQw2bWhAMRJ",
        "colab_type": "text"
      },
      "source": [
        "## Visualização dos Dados\n",
        "\n",
        "A tabela de carros usados possui os seguintes campos:<br/>\n",
        "<br/>\n",
        "* **PRECO**: Preço de venda do veículo (variável target / previsão)\n",
        "* **IDADE_ANOS**: Número de anos desde a data de fabricação do veículo\n",
        "* **KM**: Número de kilometros rodados pelo veículo\n",
        "* **TIPO_COMBUSTIVEL**: Tipo de combustível utilizado\n",
        "* **[HP](https://en.wikipedia.org/wiki/Horsepower)**: Medida de potência do veículo\n",
        "* **COR_METALICA**: Indica se o veículo possui cor metálica (1 para sim e 0 para não). Pode indicar maior valorização\n",
        "* **AUTOMATICO**: Indica se o veículo é automático (1 para sim e 0 para não)\n",
        "* **[CC](https://pt.wikipedia.org/wiki/Cilindrada)**: Cilindradas do veículo\n",
        "* **QTD_PORTAS**: Número de portas do veículo\n",
        "* **PESO_KG**: Peso em quilograma do veículo\n",
        "\n",
        "Com o comando `display(carros_usados)` podemos analisar o DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMKhrIPwAMRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados.show(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK3bmiQ0AMRe",
        "colab_type": "text"
      },
      "source": [
        "Executamos o Display do DataFrame podemos na própria célula indicar os tipos de gráficos que queremos visualizar (clicando no icone gráfico abaixo do DataFrame e em `PlotOptions`).\n",
        "\n",
        "Abaixo é possível com o comando `Display` exibir uma visualização por Tipo de Combustível e Preço (utilizando 30 `bins` [número de colunas] ) alterando-se o `Plot Options` (somente disponível para Azure Databricks)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rI8n0pdAMRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(carros_usados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVpGIB3AMRj",
        "colab_type": "text"
      },
      "source": [
        "Também podemos utilizar outras bibliotecas para análise gráfica como o `matplotlib` ou `seaborn`. Neste caso pode-se converter o DataFrame Spark para um DataFrame Pandas (com isso a performance pode ser degradada).\n",
        "\n",
        "Abaixo um [histograma](https://pt.wikipedia.org/wiki/Histograma) gerado a partir do preço de venda do veículo utilizando o matplotlib a partir de um [DataFrame do Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5y336WbAMRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "display(carros_usados.toPandas().plot(kind='hist', y='PRECO'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpGHeZBZAMRn",
        "colab_type": "text"
      },
      "source": [
        "# Criando uma regressão linear simples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HIAdKwGAMRo",
        "colab_type": "text"
      },
      "source": [
        "Podemos iniciar investigando se a idade do veículo pode influenciar seu preço de venda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AVJ-ohNAMRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados_pd = carros_usados.toPandas()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Populate the figure\n",
        "plt.scatter(carros_usados_pd['IDADE_ANOS'], carros_usados_pd['PRECO'])\n",
        "\n",
        "# Set various labels\n",
        "plt.title('Preço dos carros usados como uma função da idade')\n",
        "plt.ylabel('Preço [R$]')\n",
        "plt.xlabel('Idade [Meses]')\n",
        "\n",
        "# Extras?\n",
        "plt.grid() # Turn plot-grid on\n",
        "\n",
        "# Show figure\n",
        "display(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_SN4JJgAMRu",
        "colab_type": "text"
      },
      "source": [
        "Repare que quanto maior a idade do veículo menor o seu preço de venda (make sense??).\n",
        "\n",
        "Geralmente quando falamos em Machine Learning (aprendizado de máquina) estamos pensando em uma tarefa específica. No nosso caso, a tarefa básica \n",
        "é a de **prever o preço de venda de um veículo** utilizando para isso dados históricos de vendas de outros veículos.\n",
        "\n",
        "Regressão Linear é uma das primeiras técnicas estatísticas aprendidas para previsão de dados que se comportam de forma linear 🙄. <br/><br/>\n",
        "E o que isso significa ? Basicamente estamos falando que quando uma variável cresce (ou diminui) outra variável também têm o mesmo comportamento, como por exemplo, o **PREÇO** do veículo com a sua **IDADE** em meses (que acabamos de analisar de forma gráfica).\n",
        "\n",
        "Este comportamento, para os mais entendidos, é feito através da famosa equação \\\\(y = ax + b\\\\).\n",
        "\n",
        "No exemplo dado estamos falando apenas na relação de duas variáveis (PREÇO e IDADE), porém a ideia é utilizar diferentes variáveis no mesmo modelo linear.\n",
        "\n",
        "Neste tipo de situação (que é a mais comum) a visualização é mais complexa pois a previsão não se dará por uma única reta (mas sim por hiperplanos 😳). Quem quiser entender mais sobre isso, recomendo o vídeo [Regressão Linear Múltipla](https://drive.google.com/file/d/1MKIO-oe8mtz92rlZp3eZJIYVmQSpW0Pi/view) de uma aula dada no IME/USP sobre o assunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iNf21LDAMRv",
        "colab_type": "text"
      },
      "source": [
        "## Tratamento dos dados\n",
        "Antes de aplicarmos um modelo de Regressão Linear precisamos primeiramente tratar os dados que serão ENTRADA do modelo, isto é, precisaremos limpar, padronizar e enriquecer os dados que serão utilizados para treinamento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9IkHSeaAMRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados.show(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsHl5czwAMR_",
        "colab_type": "text"
      },
      "source": [
        "O primeiro ponto importante é analisarmos se existem valores faltantes para cada uma das colunas que serão utilizadas no modelo. \n",
        "\n",
        "Repare que existem valores `null` (faltantes) no conjunto de dados analisado. Podemos checar estes valores através do comando abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG52BWnmAMSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import isnan, when, col\n",
        "\n",
        "for c in carros_usados.columns:\n",
        "  carros_usados.where(col(c).isNull()).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egdapAjUAMSD",
        "colab_type": "text"
      },
      "source": [
        "Existem diversas técnicas de tratamento de valores faltantes (substituição pela média, moda, etc). Para simplificarmos, o processo vamos simplesmente remover toda a linha em que seja encontrado algum valor faltante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efIDWH7AMSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados = carros_usados.na.drop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRMhGT9yAMSI",
        "colab_type": "text"
      },
      "source": [
        "Outro ponto importante é analisarmos o *TIPO* das variáveis de entrada. Repare que a variável **TIPO_COMBUSTIVEL** é uma variável categórica em formato TEXTO e quando falamos em modelos de aprendizado de máquina precisamos que todas as variáveis de *INPUT* sejam de alguma forma retratadas de forma numérica. Desta forma, o modelo (que nada mais é do que uma expressão matemática, muitas vezes extremamente complexa) conseguirá utilizar os dados de forma apropriada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAcyAj5mAMSN",
        "colab_type": "text"
      },
      "source": [
        "Para tratamento da variável utilizaremos as técnicas `StringIndexer` e `OneHotEncoder` que permitem representar as varíaveis categóricas em um formato vetorial binário. \n",
        "\n",
        "Com a `StringIndexer` representaremos as varíaveis categóricas de forma numérica (ex: GASOLINA=0, DIESEL=1, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxix2Z0aAMSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol='TIPO_COMBUSTIVEL', outputCol='TIPO_COMBUSTIVEL_index')\n",
        "indexed = indexer.fit(carros_usados).transform(carros_usados)\n",
        "indexed.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnymM4krAMSR",
        "colab_type": "text"
      },
      "source": [
        "Repare que foi adicionada uma nova coluna chamada **TIPO_COMBUSTIVEL_index** com a representação numérica mencionada.\n",
        "\n",
        "Também vamos utilizar a técnica de `OneHotEncoder` para transformação vetorial binária da variável que foi indexada (uma lista mais completa das técnicas pode ser encontrada no [link](https://spark.apache.org/docs/latest/ml-features.html) ). Para otimização deste processo ainda não vamos executar as transformações, vamos criar `Stages` (estágios de processamento das transformações) que serão posteriormente colocadas em um `Pipeline`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BPJABmdAMSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(inputCols=[\"TIPO_COMBUSTIVEL_index\"],\n",
        "                                 outputCols=[\"TIPO_COMBUSTIVEL_vetor\"])\n",
        "\n",
        "stages = [indexer, encoder]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U4tVPslAMSV",
        "colab_type": "text"
      },
      "source": [
        "A variável `stages` contém os estágios de `StringIndexer` e `OneHotEncoder`, além deles utilizaremos também a técnica de `VectorAssembler` para consolidar todas as variáveis (features) que serão utilizadas para treinamento do modelo e adicionaremos mais este estágio na variável `stages`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpWEHlmwAMSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "colunas_treino = ['IDADE_ANOS', 'KM', 'HP', 'COR_METALICA', 'AUTOMATICO', 'CC', 'QTD_PORTAS', 'PESO_KG', 'TIPO_COMBUSTIVEL_vetor']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=colunas_treino, outputCol=\"features\")\n",
        "stages += [assembler]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCUKMoCAMSg",
        "colab_type": "text"
      },
      "source": [
        "Com os estágios de tratamento já definidos devemos agora dividir o conjunto de dados entre dados de treino (utilizado para treinar o modelo) e testes (utilizado para avaliar a performance do modelo). Utilizaremos a proporção de 80% para treino e 20% para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNzG0OcOAMSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "treino, teste = carros_usados.randomSplit([0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibG_LimDAMSk",
        "colab_type": "text"
      },
      "source": [
        "Com isso, finalmente 😆 podemos então realizar o treinamento de um modelo de Regressão Linear Simples.\n",
        "\n",
        "Para isso vamos adicioná-lo no [`Pipeline`](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=onehotencoder#pyspark.ml.Pipeline) em conjunto com os outros estágios de tratamento de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTd-CWSdAMSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol='PRECO')\n",
        "stages += [lr]\n",
        " \n",
        "partialPipeline = Pipeline().setStages(stages)\n",
        "model = partialPipeline.fit(treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8gvIl3cAMSv",
        "colab_type": "text"
      },
      "source": [
        "##Persistir o modelo\n",
        "\n",
        "Para ser possível a reutilização do modelo treinado podemos persisti-lo para que possa ser carregado posteriormente (sem a necessidade de re-treinamento)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6n3w_rBAMSw",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive to save sample levels as they are generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4dXwiZoTUTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tNfuJT3AMSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Persist model\n",
        "model_save_name = 'carros_usados_model'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "model.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4y5QfagWUK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "from pyspark.ml import PipelineModel\n",
        "model = PipelineModel.load(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epXmvl6QAMSz",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos também utilizar o modelo para fazer as predições na base de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0V9VvTBAMS0",
        "colab_type": "text"
      },
      "source": [
        "## Predições na base TESTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgxvAxlIAMS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicoes = model.transform(teste)\n",
        "\n",
        "predicoes.show(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yodTUue3AMS4",
        "colab_type": "text"
      },
      "source": [
        "## Podemos também analisar os resultados das predições\n",
        "\n",
        "Com o modelo treinado e as predições realizadas, vamos analisar a métrica de Erro quadrático médio [RSME](https://en.wikipedia.org/wiki/Root-mean-square_deviation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQcFhohCAMS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"PRECO\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predicoes)\n",
        "\n",
        "print(\"RMSE na base TESTE = %g\" % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcj4GNZxAMS9",
        "colab_type": "text"
      },
      "source": [
        "### Podemos comparar graficamente o \"ERRO\" das predições realizadas com relação ao valor real de PREÇO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ3t6RL7AMS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "y_pred = predicoes.toPandas().prediction\n",
        "y_test = predicoes.toPandas().PRECO\n",
        "\n",
        "# Make a list of all the errors in the test-dataset:\n",
        "errors = (y_pred - y_test)\n",
        "\n",
        "### Populate the figure\n",
        "# Plot the test-data:\n",
        "plt.scatter(teste.toPandas().PRECO, errors, color='red', edgecolors='black')\n",
        "\n",
        "# Set various labels\n",
        "plt.ylabel('ERROS')\n",
        "plt.xlabel('PREÇO')\n",
        "\n",
        "plt.title('Erros em $ por Preço')\n",
        "\n",
        "# Extras?\n",
        "plt.grid() # Turn plot-grid on\n",
        "plt.legend()\n",
        "\n",
        "# Show figure\n",
        "display(fig)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}