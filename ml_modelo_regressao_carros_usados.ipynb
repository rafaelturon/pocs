{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "name": "ml-modelo-regressao-carros-usados",
    "notebookId": 1148180762024892,
    "colab": {
      "name": "ml-modelo-regressao-carros-usados.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafaelturon/pocs/blob/master/ml_modelo_regressao_carros_usados.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvl7_kH_AMQy",
        "colab_type": "text"
      },
      "source": [
        "#Machine Learning\n",
        "###Exemplo de modelo de regress√£o p/ previs√£o de pre√ßos de venda de carros usados\n",
        "* Este tutorial foi inspirado no reposit√≥rio [Machine Learning](https://github.com/lfbraz/azure-databricks/blob/master/notebooks/ml-modelo-regressao-carros-usados.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufSmEwgoAMQ5",
        "colab_type": "text"
      },
      "source": [
        "### Neste tutorial faremos uma [regress√£o linear simples](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear_simples) em que o objetivo ser√° prever o PRE√áO (y) de venda de um determinado modelo de ve√≠culo se baseando em algumas vari√°veis de entrada (X) \n",
        "\n",
        "A base de dados utilizada pode ser obtida no [link](https://github.com/lfbraz/machine-learning-tutorial/blob/master/datasets/dataset-carros-usados.csv) e foi baseada na vers√£o [original](https://databricksdemostore.blob.core.windows.net/data/02.02/UsedCars.csv) disponibilizada pela Databricks, em que foi adaptada e traduzida para Portugu√™s-Brasil."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhwVWjSvAMQ6",
        "colab_type": "text"
      },
      "source": [
        "##Importar base de dados\n",
        "Utilizarei o [Google Colab](https://colab.research.google.com/) para treino do modelo, por√©m este tutorial pode ser utilizado com qualquer plataforma (sendo necess√°rio apenas que o m√©todo de importa√ß√£o seja adaptado)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr0pHRftGLF-",
        "colab_type": "text"
      },
      "source": [
        "# **Running Pyspark in¬†Colab**\n",
        "\n",
        "Spark is a unified analytics engine for large-scale data processing. It provides high-level APIs in Scala, Java, Python, and R, and an optimized engine that supports general computation graphs for data analysis. It also supports a rich set of higher-level tools including Spark SQL for SQL and DataFrames, MLlib for machine learning, GraphX for graph processing, and Structured Streaming for stream processing.\n",
        "\n",
        "https://spark.apache.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4vZ32bUGSP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiY9D7fXAMRB",
        "colab_type": "text"
      },
      "source": [
        "##Ler o arquivo .csv em um Spark DataFrame\n",
        "\n",
        "Utilizaremos as segmentos op√ß√µes: <br/>\n",
        "<br/>\n",
        "* format: CSV\n",
        "* inferSchema: true / Permite que os tipos de dados sejam automaticamente inferidos\n",
        "* header: true / Primeira linha ser√° entendida como o cabe√ßalho\n",
        "* sep: \";\" / Ser√° utilizado como delimitador de colunas o car√°cter \";\"\n",
        "* load: path / O caminho do arquivo que ser√° carregado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGn4CIpfAMRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pyspark\n",
        "from pyspark import SparkFiles\n",
        "\n",
        "filename = \"dataset-carros-usados.csv\"\n",
        "url = \"https://raw.githubusercontent.com/lfbraz/machine-learning-tutorial/master/datasets/{}\".format(filename)\n",
        "\n",
        "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n",
        "spark.sparkContext.addFile(url)\n",
        "\n",
        "file_type = \"csv\"\n",
        "infer_schema = \"true\"\n",
        "first_row_is_header = \"true\"\n",
        "delimiter = \";\"\n",
        "\n",
        "carros_usados = spark.read.format(file_type) \\\n",
        "                     .option(\"inferSchema\", infer_schema) \\\n",
        "                     .option(\"header\", first_row_is_header) \\\n",
        "                     .option(\"sep\", delimiter) \\\n",
        "                     .load(\"file://\"+SparkFiles.get(filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMQw2bWhAMRJ",
        "colab_type": "text"
      },
      "source": [
        "## Visualiza√ß√£o dos Dados\n",
        "\n",
        "A tabela de carros usados possui os seguintes campos:<br/>\n",
        "<br/>\n",
        "* **PRECO**: Pre√ßo de venda do ve√≠culo (vari√°vel target / previs√£o)\n",
        "* **IDADE_ANOS**: N√∫mero de anos desde a data de fabrica√ß√£o do ve√≠culo\n",
        "* **KM**: N√∫mero de kilometros rodados pelo ve√≠culo\n",
        "* **TIPO_COMBUSTIVEL**: Tipo de combust√≠vel utilizado\n",
        "* **[HP](https://en.wikipedia.org/wiki/Horsepower)**: Medida de pot√™ncia do ve√≠culo\n",
        "* **COR_METALICA**: Indica se o ve√≠culo possui cor met√°lica (1 para sim e 0 para n√£o). Pode indicar maior valoriza√ß√£o\n",
        "* **AUTOMATICO**: Indica se o ve√≠culo √© autom√°tico (1 para sim e 0 para n√£o)\n",
        "* **[CC](https://pt.wikipedia.org/wiki/Cilindrada)**: Cilindradas do ve√≠culo\n",
        "* **QTD_PORTAS**: N√∫mero de portas do ve√≠culo\n",
        "* **PESO_KG**: Peso em quilograma do ve√≠culo\n",
        "\n",
        "Com o comando `display(carros_usados)` podemos analisar o DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMKhrIPwAMRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados.show(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK3bmiQ0AMRe",
        "colab_type": "text"
      },
      "source": [
        "Executamos o Display do DataFrame podemos na pr√≥pria c√©lula indicar os tipos de gr√°ficos que queremos visualizar (clicando no icone gr√°fico abaixo do DataFrame e em `PlotOptions`).\n",
        "\n",
        "Abaixo √© poss√≠vel com o comando `Display` exibir uma visualiza√ß√£o por Tipo de Combust√≠vel e Pre√ßo (utilizando 30 `bins` [n√∫mero de colunas] ) alterando-se o `Plot Options` (somente dispon√≠vel para Azure Databricks)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rI8n0pdAMRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "display(carros_usados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huVpGIB3AMRj",
        "colab_type": "text"
      },
      "source": [
        "Tamb√©m podemos utilizar outras bibliotecas para an√°lise gr√°fica como o `matplotlib` ou `seaborn`. Neste caso pode-se converter o DataFrame Spark para um DataFrame Pandas (com isso a performance pode ser degradada).\n",
        "\n",
        "Abaixo um [histograma](https://pt.wikipedia.org/wiki/Histograma) gerado a partir do pre√ßo de venda do ve√≠culo utilizando o matplotlib a partir de um [DataFrame do Pandas](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5y336WbAMRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "display(carros_usados.toPandas().plot(kind='hist', y='PRECO'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpGHeZBZAMRn",
        "colab_type": "text"
      },
      "source": [
        "# Criando uma regress√£o linear simples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HIAdKwGAMRo",
        "colab_type": "text"
      },
      "source": [
        "Podemos iniciar investigando se a idade do ve√≠culo pode influenciar seu pre√ßo de venda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AVJ-ohNAMRp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados_pd = carros_usados.toPandas()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Populate the figure\n",
        "plt.scatter(carros_usados_pd['IDADE_ANOS'], carros_usados_pd['PRECO'])\n",
        "\n",
        "# Set various labels\n",
        "plt.title('Pre√ßo dos carros usados como uma fun√ß√£o da idade')\n",
        "plt.ylabel('Pre√ßo [R$]')\n",
        "plt.xlabel('Idade [Meses]')\n",
        "\n",
        "# Extras?\n",
        "plt.grid() # Turn plot-grid on\n",
        "\n",
        "# Show figure\n",
        "display(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_SN4JJgAMRu",
        "colab_type": "text"
      },
      "source": [
        "Repare que quanto maior a idade do ve√≠culo menor o seu pre√ßo de venda (make sense??).\n",
        "\n",
        "Geralmente quando falamos em Machine Learning (aprendizado de m√°quina) estamos pensando em uma tarefa espec√≠fica. No nosso caso, a tarefa b√°sica \n",
        "√© a de **prever o pre√ßo de venda de um ve√≠culo** utilizando para isso dados hist√≥ricos de vendas de outros ve√≠culos.\n",
        "\n",
        "Regress√£o Linear √© uma das primeiras t√©cnicas estat√≠sticas aprendidas para previs√£o de dados que se comportam de forma linear üôÑ. <br/><br/>\n",
        "E o que isso significa ? Basicamente estamos falando que quando uma vari√°vel cresce (ou diminui) outra vari√°vel tamb√©m t√™m o mesmo comportamento, como por exemplo, o **PRE√áO** do ve√≠culo com a sua **IDADE** em meses (que acabamos de analisar de forma gr√°fica).\n",
        "\n",
        "Este comportamento, para os mais entendidos, √© feito atrav√©s da famosa equa√ß√£o \\\\(y = ax + b\\\\).\n",
        "\n",
        "No exemplo dado estamos falando apenas na rela√ß√£o de duas vari√°veis (PRE√áO e IDADE), por√©m a ideia √© utilizar diferentes vari√°veis no mesmo modelo linear.\n",
        "\n",
        "Neste tipo de situa√ß√£o (que √© a mais comum) a visualiza√ß√£o √© mais complexa pois a previs√£o n√£o se dar√° por uma √∫nica reta (mas sim por hiperplanos üò≥). Quem quiser entender mais sobre isso, recomendo o v√≠deo [Regress√£o Linear M√∫ltipla](https://drive.google.com/file/d/1MKIO-oe8mtz92rlZp3eZJIYVmQSpW0Pi/view) de uma aula dada no IME/USP sobre o assunto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iNf21LDAMRv",
        "colab_type": "text"
      },
      "source": [
        "## Tratamento dos dados\n",
        "Antes de aplicarmos um modelo de Regress√£o Linear precisamos primeiramente tratar os dados que ser√£o ENTRADA do modelo, isto √©, precisaremos limpar, padronizar e enriquecer os dados que ser√£o utilizados para treinamento do modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9IkHSeaAMRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados.show(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsHl5czwAMR_",
        "colab_type": "text"
      },
      "source": [
        "O primeiro ponto importante √© analisarmos se existem valores faltantes para cada uma das colunas que ser√£o utilizadas no modelo. \n",
        "\n",
        "Repare que existem valores `null` (faltantes) no conjunto de dados analisado. Podemos checar estes valores atrav√©s do comando abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG52BWnmAMSA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql.functions import isnan, when, col\n",
        "\n",
        "for c in carros_usados.columns:\n",
        "  carros_usados.where(col(c).isNull()).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egdapAjUAMSD",
        "colab_type": "text"
      },
      "source": [
        "Existem diversas t√©cnicas de tratamento de valores faltantes (substitui√ß√£o pela m√©dia, moda, etc). Para simplificarmos, o processo vamos simplesmente remover toda a linha em que seja encontrado algum valor faltante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1efIDWH7AMSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "carros_usados = carros_usados.na.drop()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRMhGT9yAMSI",
        "colab_type": "text"
      },
      "source": [
        "Outro ponto importante √© analisarmos o *TIPO* das vari√°veis de entrada. Repare que a vari√°vel **TIPO_COMBUSTIVEL** √© uma vari√°vel categ√≥rica em formato TEXTO e quando falamos em modelos de aprendizado de m√°quina precisamos que todas as vari√°veis de *INPUT* sejam de alguma forma retratadas de forma num√©rica. Desta forma, o modelo (que nada mais √© do que uma express√£o matem√°tica, muitas vezes extremamente complexa) conseguir√° utilizar os dados de forma apropriada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAcyAj5mAMSN",
        "colab_type": "text"
      },
      "source": [
        "Para tratamento da vari√°vel utilizaremos as t√©cnicas `StringIndexer` e `OneHotEncoder` que permitem representar as var√≠aveis categ√≥ricas em um formato vetorial bin√°rio. \n",
        "\n",
        "Com a `StringIndexer` representaremos as var√≠aveis categ√≥ricas de forma num√©rica (ex: GASOLINA=0, DIESEL=1, etc)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxix2Z0aAMSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexer = StringIndexer(inputCol='TIPO_COMBUSTIVEL', outputCol='TIPO_COMBUSTIVEL_index')\n",
        "indexed = indexer.fit(carros_usados).transform(carros_usados)\n",
        "indexed.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnymM4krAMSR",
        "colab_type": "text"
      },
      "source": [
        "Repare que foi adicionada uma nova coluna chamada **TIPO_COMBUSTIVEL_index** com a representa√ß√£o num√©rica mencionada.\n",
        "\n",
        "Tamb√©m vamos utilizar a t√©cnica de `OneHotEncoder` para transforma√ß√£o vetorial bin√°ria da vari√°vel que foi indexada (uma lista mais completa das t√©cnicas pode ser encontrada no [link](https://spark.apache.org/docs/latest/ml-features.html) ). Para otimiza√ß√£o deste processo ainda n√£o vamos executar as transforma√ß√µes, vamos criar `Stages` (est√°gios de processamento das transforma√ß√µes) que ser√£o posteriormente colocadas em um `Pipeline`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BPJABmdAMSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "encoder = OneHotEncoder(inputCols=[\"TIPO_COMBUSTIVEL_index\"],\n",
        "                                 outputCols=[\"TIPO_COMBUSTIVEL_vetor\"])\n",
        "\n",
        "stages = [indexer, encoder]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U4tVPslAMSV",
        "colab_type": "text"
      },
      "source": [
        "A vari√°vel `stages` cont√©m os est√°gios de `StringIndexer` e `OneHotEncoder`, al√©m deles utilizaremos tamb√©m a t√©cnica de `VectorAssembler` para consolidar todas as vari√°veis (features) que ser√£o utilizadas para treinamento do modelo e adicionaremos mais este est√°gio na vari√°vel `stages`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpWEHlmwAMSW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "colunas_treino = ['IDADE_ANOS', 'KM', 'HP', 'COR_METALICA', 'AUTOMATICO', 'CC', 'QTD_PORTAS', 'PESO_KG', 'TIPO_COMBUSTIVEL_vetor']\n",
        "\n",
        "assembler = VectorAssembler(inputCols=colunas_treino, outputCol=\"features\")\n",
        "stages += [assembler]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqCUKMoCAMSg",
        "colab_type": "text"
      },
      "source": [
        "Com os est√°gios de tratamento j√° definidos devemos agora dividir o conjunto de dados entre dados de treino (utilizado para treinar o modelo) e testes (utilizado para avaliar a performance do modelo). Utilizaremos a propor√ß√£o de 80% para treino e 20% para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNzG0OcOAMSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "treino, teste = carros_usados.randomSplit([0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibG_LimDAMSk",
        "colab_type": "text"
      },
      "source": [
        "Com isso, finalmente üòÜ podemos ent√£o realizar o treinamento de um modelo de Regress√£o Linear Simples.\n",
        "\n",
        "Para isso vamos adicion√°-lo no [`Pipeline`](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html?highlight=onehotencoder#pyspark.ml.Pipeline) em conjunto com os outros est√°gios de tratamento de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTd-CWSdAMSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol='PRECO')\n",
        "stages += [lr]\n",
        " \n",
        "partialPipeline = Pipeline().setStages(stages)\n",
        "model = partialPipeline.fit(treino)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8gvIl3cAMSv",
        "colab_type": "text"
      },
      "source": [
        "##Persistir o modelo\n",
        "\n",
        "Para ser poss√≠vel a reutiliza√ß√£o do modelo treinado podemos persisti-lo para que possa ser carregado posteriormente (sem a necessidade de re-treinamento)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6n3w_rBAMSw",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive to save sample levels as they are generated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4dXwiZoTUTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tNfuJT3AMSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Persist model\n",
        "model_save_name = 'carros_usados_model'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "model.save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4y5QfagWUK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "from pyspark.ml import PipelineModel\n",
        "model = PipelineModel.load(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epXmvl6QAMSz",
        "colab_type": "text"
      },
      "source": [
        "Agora podemos tamb√©m utilizar o modelo para fazer as predi√ß√µes na base de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0V9VvTBAMS0",
        "colab_type": "text"
      },
      "source": [
        "## Predi√ß√µes na base TESTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgxvAxlIAMS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicoes = model.transform(teste)\n",
        "\n",
        "predicoes.show(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yodTUue3AMS4",
        "colab_type": "text"
      },
      "source": [
        "## Podemos tamb√©m analisar os resultados das predi√ß√µes\n",
        "\n",
        "Com o modelo treinado e as predi√ß√µes realizadas, vamos analisar a m√©trica de Erro quadr√°tico m√©dio [RSME](https://en.wikipedia.org/wiki/Root-mean-square_deviation)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQcFhohCAMS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "\n",
        "evaluator = RegressionEvaluator(labelCol=\"PRECO\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
        "rmse = evaluator.evaluate(predicoes)\n",
        "\n",
        "print(\"RMSE na base TESTE = %g\" % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcj4GNZxAMS9",
        "colab_type": "text"
      },
      "source": [
        "### Podemos comparar graficamente o \"ERRO\" das predi√ß√µes realizadas com rela√ß√£o ao valor real de PRE√áO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ3t6RL7AMS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "y_pred = predicoes.toPandas().prediction\n",
        "y_test = predicoes.toPandas().PRECO\n",
        "\n",
        "# Make a list of all the errors in the test-dataset:\n",
        "errors = (y_pred - y_test)\n",
        "\n",
        "### Populate the figure\n",
        "# Plot the test-data:\n",
        "plt.scatter(teste.toPandas().PRECO, errors, color='red', edgecolors='black')\n",
        "\n",
        "# Set various labels\n",
        "plt.ylabel('ERROS')\n",
        "plt.xlabel('PRE√áO')\n",
        "\n",
        "plt.title('Erros em $ por Pre√ßo')\n",
        "\n",
        "# Extras?\n",
        "plt.grid() # Turn plot-grid on\n",
        "plt.legend()\n",
        "\n",
        "# Show figure\n",
        "display(fig)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}